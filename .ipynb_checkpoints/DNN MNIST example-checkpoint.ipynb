{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "#from keras.optimizers import adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class AdamOptimizer(tf.train.Optimizer):\n",
    "\tdef __init__(self, alpha=0.001, \n",
    "\t\t\t\t\t\tbeta1=0.9, \n",
    "\t\t\t\t\t\tbeta2=0.999,\n",
    "\t\t\t\t\t\tepsilon=1e-8):\n",
    "\t\t\n",
    "\t\tself.alpha = alpha\n",
    "\t\tself.beta1 = beta1\n",
    "\t\tself.beta2 = beta2\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\t\n",
    "\t\tself.m = {}\n",
    "\t\tself.u = {}\n",
    "\t\tself.t = tf.Variable(0.0, trainable=False)\n",
    "\t\t\n",
    "\t\tfor v in tf.trainable_variables():\n",
    "\t\t\tself.m[v] = tf.Variable(tf.zeros(tf.shape(v.initial_value)), trainable=False)\n",
    "\t\t\tself.u[v] = tf.Variable(tf.zeros(tf.shape(v.initial_value)), trainable=False)\n",
    "\n",
    "\n",
    "\tdef apply_gradients(self,gvs):\n",
    "\t\tt = self.t.assign_add(1.0)\n",
    "\n",
    "\t\tupdate_ops = []\n",
    "\t\tfor (g,v) in gvs:\n",
    "\t\t\tm = self.m[v].assign(self.beta1*self.m[v] + (1-self.beta1)*g)\n",
    "\t\t\tu = self.u[v].assign(self.beta2*self.u[v] + (1-self.beta2)*g*g)\n",
    "\t\t\tm_hat = m/(1-tf.pow(self.beta1,t))\n",
    "\t\t\tu_hat = u/(1-tf.pow(self.beta2,t))\n",
    "\t\t\t\n",
    "\t\t\tupdate = -self.alpha*m_hat/(tf.sqrt(u_hat) + self.epsilon)\n",
    "\t\t\tupdate_ops.append(v.assign_add(update))\n",
    "\t\t\t\n",
    "\t\treturn tf.group(*update_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adam import AdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Adam for TensorFlow.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.python.eager import context\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import resource_variable_ops\n",
    "from tensorflow.python.ops import state_ops\n",
    "from tensorflow.python.training import optimizer\n",
    "from tensorflow.python.training import training_ops\n",
    "from tensorflow.python.util.tf_export import tf_export\n",
    "\n",
    "\n",
    "@tf_export(\"train.AdamOptimizer\")\n",
    "class AdamOptimizer(optimizer.Optimizer):\n",
    "  \"\"\"Optimizer that implements the Adam algorithm.\n",
    "\n",
    "  See [Kingma et al., 2014](http://arxiv.org/abs/1412.6980)\n",
    "  ([pdf](http://arxiv.org/pdf/1412.6980.pdf)).\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8,\n",
    "               use_locking=False, name=\"Adam\"):\n",
    "    \"\"\"Construct a new Adam optimizer.\n",
    "\n",
    "    Initialization:\n",
    "\n",
    "    ```\n",
    "    m_0 <- 0 (Initialize initial 1st moment vector)\n",
    "    v_0 <- 0 (Initialize initial 2nd moment vector)\n",
    "    t <- 0 (Initialize timestep)\n",
    "    ```\n",
    "\n",
    "    The update rule for `variable` with gradient `g` uses an optimization\n",
    "    described at the end of section2 of the paper:\n",
    "\n",
    "    ```\n",
    "    t <- t + 1\n",
    "    lr_t <- learning_rate * sqrt(1 - beta2^t) / (1 - beta1^t)\n",
    "\n",
    "    m_t <- beta1 * m_{t-1} + (1 - beta1) * g\n",
    "    v_t <- beta2 * v_{t-1} + (1 - beta2) * g * g\n",
    "    variable <- variable - lr_t * m_t / (sqrt(v_t) + epsilon)\n",
    "    ```\n",
    "\n",
    "    The default value of 1e-8 for epsilon might not be a good default in\n",
    "    general. For example, when training an Inception network on ImageNet a\n",
    "    current good choice is 1.0 or 0.1. Note that since AdamOptimizer uses the\n",
    "    formulation just before Section 2.1 of the Kingma and Ba paper rather than\n",
    "    the formulation in Algorithm 1, the \"epsilon\" referred to here is \"epsilon\n",
    "    hat\" in the paper.\n",
    "\n",
    "    The sparse implementation of this algorithm (used when the gradient is an\n",
    "    IndexedSlices object, typically because of `tf.gather` or an embedding\n",
    "    lookup in the forward pass) does apply momentum to variable slices even if\n",
    "    they were not used in the forward pass (meaning they have a gradient equal\n",
    "    to zero). Momentum decay (beta1) is also applied to the entire momentum\n",
    "    accumulator. This means that the sparse behavior is equivalent to the dense\n",
    "    behavior (in contrast to some momentum implementations which ignore momentum\n",
    "    unless a variable slice was actually used).\n",
    "\n",
    "    Args:\n",
    "      learning_rate: A Tensor or a floating point value.  The learning rate.\n",
    "      beta1: A float value or a constant float tensor.\n",
    "        The exponential decay rate for the 1st moment estimates.\n",
    "      beta2: A float value or a constant float tensor.\n",
    "        The exponential decay rate for the 2nd moment estimates.\n",
    "      epsilon: A small constant for numerical stability. This epsilon is\n",
    "        \"epsilon hat\" in the Kingma and Ba paper (in the formula just before\n",
    "        Section 2.1), not the epsilon in Algorithm 1 of the paper.\n",
    "      use_locking: If True use locks for update operations.\n",
    "      name: Optional name for the operations created when applying gradients.\n",
    "        Defaults to \"Adam\".\n",
    "    \"\"\"\n",
    "    super(AdamOptimizer, self).__init__(use_locking, name)\n",
    "    self._lr = learning_rate\n",
    "    self._beta1 = beta1\n",
    "    self._beta2 = beta2\n",
    "    self._epsilon = epsilon\n",
    "\n",
    "    # Tensor versions of the constructor arguments, created in _prepare().\n",
    "    self._lr_t = None\n",
    "    self._beta1_t = None\n",
    "    self._beta2_t = None\n",
    "    self._epsilon_t = None\n",
    "\n",
    "    # Created in SparseApply if needed.\n",
    "    self._updated_lr = None\n",
    "\n",
    "  def _get_beta_accumulators(self):\n",
    "    if context.executing_eagerly():\n",
    "      graph = None\n",
    "    else:\n",
    "      graph = ops.get_default_graph()\n",
    "    return (self._get_non_slot_variable(\"beta1_power\", graph=graph),\n",
    "            self._get_non_slot_variable(\"beta2_power\", graph=graph))\n",
    "\n",
    "  def _create_slots(self, var_list):\n",
    "    # Create the beta1 and beta2 accumulators on the same device as the first\n",
    "    # variable. Sort the var_list to make sure this device is consistent across\n",
    "    # workers (these need to go on the same PS, otherwise some updates are\n",
    "    # silently ignored).\n",
    "    first_var = min(var_list, key=lambda x: x.name)\n",
    "    self._create_non_slot_variable(initial_value=self._beta1,\n",
    "                                   name=\"beta1_power\",\n",
    "                                   colocate_with=first_var)\n",
    "    self._create_non_slot_variable(initial_value=self._beta2,\n",
    "                                   name=\"beta2_power\",\n",
    "                                   colocate_with=first_var)\n",
    "\n",
    "    # Create slots for the first and second moments.\n",
    "    for v in var_list:\n",
    "      self._zeros_slot(v, \"m\", self._name)\n",
    "      self._zeros_slot(v, \"v\", self._name)\n",
    "\n",
    "  def _prepare(self):\n",
    "    self._lr_t = ops.convert_to_tensor(self._lr, name=\"learning_rate\")\n",
    "    self._beta1_t = ops.convert_to_tensor(self._beta1, name=\"beta1\")\n",
    "    self._beta2_t = ops.convert_to_tensor(self._beta2, name=\"beta2\")\n",
    "    self._epsilon_t = ops.convert_to_tensor(self._epsilon, name=\"epsilon\")\n",
    "\n",
    "  def _apply_dense(self, grad, var):\n",
    "    m = self.get_slot(var, \"m\")\n",
    "    v = self.get_slot(var, \"v\")\n",
    "    beta1_power, beta2_power = self._get_beta_accumulators()\n",
    "    return training_ops.apply_adam(\n",
    "        var, m, v,\n",
    "        math_ops.cast(beta1_power, var.dtype.base_dtype),\n",
    "        math_ops.cast(beta2_power, var.dtype.base_dtype),\n",
    "        math_ops.cast(self._lr_t, var.dtype.base_dtype),\n",
    "        math_ops.cast(self._beta1_t, var.dtype.base_dtype),\n",
    "        math_ops.cast(self._beta2_t, var.dtype.base_dtype),\n",
    "        math_ops.cast(self._epsilon_t, var.dtype.base_dtype),\n",
    "        grad, use_locking=self._use_locking).op\n",
    "\n",
    "  def _resource_apply_dense(self, grad, var):\n",
    "    m = self.get_slot(var, \"m\")\n",
    "    v = self.get_slot(var, \"v\")\n",
    "    beta1_power, beta2_power = self._get_beta_accumulators()\n",
    "    return training_ops.resource_apply_adam(\n",
    "        var.handle, m.handle, v.handle,\n",
    "        math_ops.cast(beta1_power, grad.dtype.base_dtype),\n",
    "        math_ops.cast(beta2_power, grad.dtype.base_dtype),\n",
    "        math_ops.cast(self._lr_t, grad.dtype.base_dtype),\n",
    "        math_ops.cast(self._beta1_t, grad.dtype.base_dtype),\n",
    "        math_ops.cast(self._beta2_t, grad.dtype.base_dtype),\n",
    "        math_ops.cast(self._epsilon_t, grad.dtype.base_dtype),\n",
    "        grad, use_locking=self._use_locking)\n",
    "\n",
    "  def _apply_sparse_shared(self, grad, var, indices, scatter_add):\n",
    "    beta1_power, beta2_power = self._get_beta_accumulators()\n",
    "    beta1_power = math_ops.cast(beta1_power, var.dtype.base_dtype)\n",
    "    beta2_power = math_ops.cast(beta2_power, var.dtype.base_dtype)\n",
    "    lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n",
    "    beta1_t = math_ops.cast(self._beta1_t, var.dtype.base_dtype)\n",
    "    beta2_t = math_ops.cast(self._beta2_t, var.dtype.base_dtype)\n",
    "    epsilon_t = math_ops.cast(self._epsilon_t, var.dtype.base_dtype)\n",
    "    lr = (lr_t * math_ops.sqrt(1 - beta2_power) / (1 - beta1_power))\n",
    "    # m_t = beta1 * m + (1 - beta1) * g_t\n",
    "    m = self.get_slot(var, \"m\")\n",
    "    m_scaled_g_values = grad * (1 - beta1_t)\n",
    "    m_t = state_ops.assign(m, m * beta1_t,\n",
    "                           use_locking=self._use_locking)\n",
    "    with ops.control_dependencies([m_t]):\n",
    "      m_t = scatter_add(m, indices, m_scaled_g_values)\n",
    "    # v_t = beta2 * v + (1 - beta2) * (g_t * g_t)\n",
    "    v = self.get_slot(var, \"v\")\n",
    "    v_scaled_g_values = (grad * grad) * (1 - beta2_t)\n",
    "    v_t = state_ops.assign(v, v * beta2_t, use_locking=self._use_locking)\n",
    "    with ops.control_dependencies([v_t]):\n",
    "      v_t = scatter_add(v, indices, v_scaled_g_values)\n",
    "    v_sqrt = math_ops.sqrt(v_t)\n",
    "    var_update = state_ops.assign_sub(var,\n",
    "                                      lr * m_t / (v_sqrt + epsilon_t),\n",
    "                                      use_locking=self._use_locking)\n",
    "    return control_flow_ops.group(*[var_update, m_t, v_t])\n",
    "\n",
    "  def _apply_sparse(self, grad, var):\n",
    "    return self._apply_sparse_shared(\n",
    "        grad.values, var, grad.indices,\n",
    "        lambda x, i, v: state_ops.scatter_add(  # pylint: disable=g-long-lambda\n",
    "            x, i, v, use_locking=self._use_locking))\n",
    "\n",
    "  def _resource_scatter_add(self, x, i, v):\n",
    "    with ops.control_dependencies(\n",
    "        [resource_variable_ops.resource_scatter_add(\n",
    "            x.handle, i, v)]):\n",
    "      return x.value()\n",
    "\n",
    "  def _resource_apply_sparse(self, grad, var, indices):\n",
    "    return self._apply_sparse_shared(\n",
    "        grad, var, indices, self._resource_scatter_add)\n",
    "\n",
    "  def _finish(self, update_ops, name_scope):\n",
    "    # Update the power accumulators.\n",
    "    with ops.control_dependencies(update_ops):\n",
    "      beta1_power, beta2_power = self._get_beta_accumulators()\n",
    "      with ops.colocate_with(beta1_power):\n",
    "        update_beta1 = beta1_power.assign(\n",
    "            beta1_power * self._beta1_t, use_locking=self._use_locking)\n",
    "        update_beta2 = beta2_power.assign(\n",
    "            beta2_power * self._beta2_t, use_locking=self._use_locking)\n",
    "    return control_flow_ops.group(*update_ops + [update_beta1, update_beta2],\n",
    "                                  name=name_scope)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "def _create_slots(self, var_list):\n",
    "     # Create slots for allocation and later management of additional \n",
    "     # variables associated with the variables to train.\n",
    "     # for example: the first and second moments.\n",
    "     '''\n",
    "     for v in var_list:\n",
    "     self._zeros_slot(v, \"m\", self._name)\n",
    "     self._zeros_slot(v, \"v\", self._name)\n",
    "     '''\n",
    "def _apply_dense(self, grad, var):\n",
    "     # Define your favourite variable update\n",
    "     # For example:\n",
    "     '''\n",
    "     var_update = state_ops.assign_sub(var, self.learning_rate * grad) \n",
    "     '''\n",
    "     # The trick is now to pass the Ops in the control_flow_ops and \n",
    "     # eventually groups any particular computation of the slots your \n",
    "     # wish to keep track of:\n",
    "     # for example:    \n",
    "     '''\n",
    "     m_t = ...m... #do something with m and grad\n",
    "     v_t = ...v... # do something with v and grad\n",
    "     '''\n",
    "     return control_flow_ops.group(*[var_update, m_t, v_t])\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import state_ops\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.training import optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "class PowerSign(optimizer.Optimizer):\n",
    "    \"\"\"Implementation of PowerSign.\n",
    "    See [Bello et. al., 2017](https://arxiv.org/abs/1709.07417)\n",
    "    @@__init__\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.001,alpha=0.01,beta=0.5, use_locking=False, name=\"PowerSign\"):\n",
    "        super(PowerSign, self).__init__(use_locking, name)\n",
    "        self._lr = learning_rate\n",
    "        self._alpha = alpha\n",
    "        self._beta = beta\n",
    "        \n",
    "        # Tensor versions of the constructor arguments, created in _prepare().\n",
    "        self._lr_t = None\n",
    "        self._alpha_t = None\n",
    "        self._beta_t = None\n",
    "\n",
    "    def _prepare(self):\n",
    "        self._lr_t = ops.convert_to_tensor(self._lr, name=\"learning_rate\")\n",
    "        self._alpha_t = ops.convert_to_tensor(self._beta, name=\"alpha_t\")\n",
    "        self._beta_t = ops.convert_to_tensor(self._beta, name=\"beta_t\")\n",
    "\n",
    "    def _create_slots(self, var_list):\n",
    "        # Create slots for the first and second moments.\n",
    "        for v in var_list:\n",
    "            self._zeros_slot(v, \"m\", self._name)\n",
    "\n",
    "    def _apply_dense(self, grad, var):\n",
    "        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n",
    "        alpha_t = math_ops.cast(self._alpha_t, var.dtype.base_dtype)\n",
    "        beta_t = math_ops.cast(self._beta_t, var.dtype.base_dtype)\n",
    "\n",
    "        eps = 1e-7 #cap for moving average\n",
    "        \n",
    "        m = self.get_slot(var, \"m\")\n",
    "        m_t = m.assign(tf.maximum(beta_t * m + eps, tf.abs(grad)))\n",
    "\n",
    "        var_update = state_ops.assign_sub(var, lr_t*grad*tf.exp( tf.log(alpha_t)*tf.sign(grad)*tf.sign(m_t))) #Update 'ref' by subtracting 'value\n",
    "        #Create an op that groups multiple operations.\n",
    "        #When this op finishes, all ops in input have finished\n",
    "        return control_flow_ops.group(*[var_update, m_t])\n",
    "\n",
    "    def _apply_sparse(self, grad, var):\n",
    "        raise NotImplementedError(\"Sparse gradient updates are not supported.\")\n",
    "        \n",
    "class AddSign(optimizer.Optimizer):\n",
    "    \"\"\"Implementation of AddSign.\n",
    "    See [Bello et. al., 2017](https://arxiv.org/abs/1709.07417)\n",
    "    @@__init__\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate=1.001,alpha=0.01,beta=0.5, use_locking=False, name=\"AddSign\"):\n",
    "        super(AddSign, self).__init__(use_locking, name)\n",
    "        self._lr = learning_rate\n",
    "        self._alpha = alpha\n",
    "        self._beta = beta\n",
    "        \n",
    "        # Tensor versions of the constructor arguments, created in _prepare().\n",
    "        self._lr_t = None\n",
    "        self._alpha_t = None\n",
    "        self._beta_t = None\n",
    "      \n",
    "    def _prepare(self):\n",
    "        self._lr_t = ops.convert_to_tensor(self._lr, name=\"learning_rate\")\n",
    "        self._alpha_t = ops.convert_to_tensor(self._beta, name=\"beta_t\")\n",
    "        self._beta_t = ops.convert_to_tensor(self._beta, name=\"beta_t\")\n",
    "\n",
    "    def _create_slots(self, var_list):\n",
    "        # Create slots for the first and second moments.\n",
    "        for v in var_list:\n",
    "            self._zeros_slot(v, \"m\", self._name)\n",
    "\n",
    "    def _apply_dense(self, grad, var):\n",
    "        lr_t = math_ops.cast(self._lr_t, var.dtype.base_dtype)\n",
    "        beta_t = math_ops.cast(self._beta_t, var.dtype.base_dtype)\n",
    "        alpha_t = math_ops.cast(self._alpha_t, var.dtype.base_dtype)\n",
    "    \n",
    "        eps = 1e-7 #cap for moving average\n",
    "        \n",
    "        m = self.get_slot(var, \"m\")\n",
    "        m_t = m.assign(tf.maximum(beta_t * m + eps, tf.abs(grad)))\n",
    "        \n",
    "        var_update = state_ops.assign_sub(var, lr_t*grad*(1.0+alpha_t*tf.sign(grad)*tf.sign(m_t) ) )\n",
    "        #Create an op that groups multiple operations\n",
    "        #When this op finishes, all ops in input have finished\n",
    "        return control_flow_ops.group(*[var_update, m_t])\n",
    "\n",
    "    def _apply_sparse(self, grad, var):\n",
    "        raise NotImplementedError(\"Sparse gradient updates are not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RosenbrockOpt(optimizer,MAX_EPOCHS = 4000, MAX_STEP = 100):\n",
    "   '''\n",
    "   returns distance of each step*MAX_STEP w.r.t minimum (1,1)\n",
    "   '''\n",
    "   x1_data = tf.Variable(initial_value=tf.random_uniform([1], minval=-3, maxval=3,seed=0),name='x1')\n",
    "   x2_data = tf.Variable(initial_value=tf.random_uniform([1], minval=-3, maxval=3,seed=1), name='x2')\n",
    "\n",
    "   y = tf.add(tf.pow(tf.subtract(1.0, x1_data), 2.0),\n",
    "   tf.multiply(100.0, tf.pow(tf.subtract(x2_data, tf.pow(x1_data, 2.0)), 2.0)), 'y')\n",
    "\n",
    "   global_step_tensor = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "   train = optimizer.minimize(y,global_step=global_step_tensor)\n",
    "\n",
    "   sess = tf.Session()\n",
    "\n",
    "   init = tf.global_variables_initializer()#tf.initialize_all_variables()\n",
    "   sess.run(init)\n",
    "\n",
    "   minx = 1.0\n",
    "   miny = 1.0\n",
    "\n",
    "   distance = []\n",
    "   xx_ = sess.run(x1_data)\n",
    "   yy_ = sess.run(x2_data)\n",
    "   print(0,xx_,yy_,np.sqrt((minx-xx_)**2+(miny-yy_)**2))\n",
    "   for step in range(MAX_EPOCHS):\n",
    "      _, xx_, yy_, zz_ = sess.run([train,x1_data,x2_data,y])\n",
    "      if step % MAX_STEP == 0:\n",
    "         print(step+1, xx_,yy_, zz_)\n",
    "         distance += [ np.sqrt((minx-xx_)**2+(miny-yy_)**2)]\n",
    "         sess.close()\n",
    "         return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "apply_gradients() got an unexpected keyword argument 'global_step'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2398ef431728>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                     validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/tf/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda2/envs/tf/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/tf/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    989\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    991\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m                 \u001b[0;31m# Gets loss and metrics. Updates weights at each call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/tf/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/tf/lib/python2.7/site-packages/keras/optimizers.pyc\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         opt_update = self.optimizer.apply_gradients(\n\u001b[0;32m--> 676\u001b[0;31m             grads, global_step=self.iterations)\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: apply_gradients() got an unexpected keyword argument 'global_step'"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=AdamOptimizer(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
